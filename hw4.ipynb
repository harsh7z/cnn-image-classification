{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4O5Dlc5_6yT5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgD_coEM6yT6",
        "outputId": "7fd893eb-7824-4177-dafe-bf2fd664076c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize : [0,1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "hMJ8LAYa6yT7"
      },
      "outputs": [],
      "source": [
        "def CNN():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2), strides=2),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2), strides=2),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2), strides=2),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RqQJI9z56yT8",
        "outputId": "b0a81c52-e6d4-400a-c8dd-1936ecd7f445"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.2699 - loss: 1.9444 - val_accuracy: 0.4606 - val_loss: 1.4574\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4903 - loss: 1.3951 - val_accuracy: 0.5557 - val_loss: 1.2383\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5679 - loss: 1.2146 - val_accuracy: 0.5982 - val_loss: 1.1514\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6226 - loss: 1.0661 - val_accuracy: 0.6294 - val_loss: 1.0448\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6633 - loss: 0.9564 - val_accuracy: 0.6552 - val_loss: 0.9819\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6959 - loss: 0.8748 - val_accuracy: 0.6827 - val_loss: 0.9132\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7170 - loss: 0.8085 - val_accuracy: 0.6935 - val_loss: 0.8912\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7395 - loss: 0.7511 - val_accuracy: 0.6883 - val_loss: 0.9111\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7549 - loss: 0.6974 - val_accuracy: 0.7086 - val_loss: 0.8594\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7724 - loss: 0.6476 - val_accuracy: 0.7197 - val_loss: 0.8278\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7891 - loss: 0.6088 - val_accuracy: 0.7269 - val_loss: 0.8236\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8050 - loss: 0.5599 - val_accuracy: 0.7142 - val_loss: 0.8614\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8161 - loss: 0.5321 - val_accuracy: 0.7152 - val_loss: 0.8994\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8260 - loss: 0.4962 - val_accuracy: 0.7163 - val_loss: 0.8922\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8390 - loss: 0.4597 - val_accuracy: 0.7150 - val_loss: 0.9060\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8502 - loss: 0.4243 - val_accuracy: 0.7195 - val_loss: 0.9195\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8633 - loss: 0.3926 - val_accuracy: 0.7222 - val_loss: 0.9472\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8768 - loss: 0.3502 - val_accuracy: 0.7199 - val_loss: 0.9562\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8766 - loss: 0.3459 - val_accuracy: 0.7136 - val_loss: 1.0345\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8862 - loss: 0.3171 - val_accuracy: 0.7188 - val_loss: 1.0467\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7221 - loss: 1.0358\n",
            "Test accuracy:  71.88000082969666 %\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy: ', accuracy * 100, '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gVdtaovs83UQ"
      },
      "outputs": [],
      "source": [
        "def UPDATED_CNN():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        # Batch normalization to normalized activations\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2), strides=2),\n",
        "        # Dropout layer to prevent overfitting\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        # Batch Normalization to normalized activations\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2), strides=2),\n",
        "        # Dropout layer to prevent overfitting\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        # Batch Normalization to normalized activations\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2), strides=2),\n",
        "        # Dropout layer to prevent overfitting\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        # Dropout layer to prevent overfitting\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spxMlUAB-YBE",
        "outputId": "5ba85929-5e95-49d8-c43e-dc471abe2a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - accuracy: 0.2859 - loss: 2.1614 - val_accuracy: 0.2728 - val_loss: 2.7251\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4803 - loss: 1.4347 - val_accuracy: 0.5700 - val_loss: 1.1919\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5627 - loss: 1.2260 - val_accuracy: 0.5956 - val_loss: 1.1241\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6150 - loss: 1.0939 - val_accuracy: 0.5985 - val_loss: 1.1518\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6429 - loss: 1.0015 - val_accuracy: 0.6920 - val_loss: 0.8732\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6747 - loss: 0.9150 - val_accuracy: 0.6495 - val_loss: 1.0677\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6968 - loss: 0.8553 - val_accuracy: 0.7313 - val_loss: 0.7825\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7148 - loss: 0.8102 - val_accuracy: 0.7376 - val_loss: 0.7644\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7272 - loss: 0.7742 - val_accuracy: 0.7389 - val_loss: 0.7592\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7379 - loss: 0.7413 - val_accuracy: 0.7227 - val_loss: 0.8185\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7471 - loss: 0.7145 - val_accuracy: 0.7531 - val_loss: 0.7188\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7556 - loss: 0.7004 - val_accuracy: 0.7717 - val_loss: 0.6629\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7626 - loss: 0.6736 - val_accuracy: 0.7783 - val_loss: 0.6676\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7702 - loss: 0.6565 - val_accuracy: 0.7890 - val_loss: 0.6341\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7797 - loss: 0.6326 - val_accuracy: 0.7784 - val_loss: 0.6820\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7823 - loss: 0.6283 - val_accuracy: 0.7801 - val_loss: 0.6746\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7868 - loss: 0.6118 - val_accuracy: 0.7833 - val_loss: 0.6626\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7963 - loss: 0.5832 - val_accuracy: 0.7477 - val_loss: 0.7848\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7961 - loss: 0.5784 - val_accuracy: 0.7903 - val_loss: 0.6422\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7998 - loss: 0.5687 - val_accuracy: 0.7934 - val_loss: 0.6305\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.6270\n",
            "Test accuracy:  79.339998960495 %\n"
          ]
        }
      ],
      "source": [
        "model = UPDATED_CNN()\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy: ', accuracy * 100, '%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hw2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
